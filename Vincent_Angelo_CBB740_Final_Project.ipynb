{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "from joblib import parallel_backend\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"Eczema\" for domain \"person\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_57765325_person_sql = \"\"\"\n",
    "    SELECT\n",
    "        person.person_id,\n",
    "        person.gender_concept_id,\n",
    "        p_gender_concept.concept_name as gender,\n",
    "        person.birth_datetime as date_of_birth,\n",
    "        person.race_concept_id,\n",
    "        p_race_concept.concept_name as race,\n",
    "        person.ethnicity_concept_id,\n",
    "        p_ethnicity_concept.concept_name as ethnicity,\n",
    "        person.sex_at_birth_concept_id,\n",
    "        p_sex_at_birth_concept.concept_name as sex_at_birth \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".person` person \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_gender_concept \n",
    "            ON person.gender_concept_id = p_gender_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_race_concept \n",
    "            ON person.race_concept_id = p_race_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_ethnicity_concept \n",
    "            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_sex_at_birth_concept \n",
    "            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id  \n",
    "    WHERE\n",
    "        person.PERSON_ID IN (SELECT\n",
    "            distinct person_id  \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "        WHERE\n",
    "            cb_search_person.person_id IN (SELECT\n",
    "                criteria.person_id \n",
    "            FROM\n",
    "                (SELECT\n",
    "                    DISTINCT person_id, entry_date, concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                WHERE\n",
    "                    (concept_id IN(SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                    JOIN\n",
    "                        (SELECT\n",
    "                            CAST(cr.id as string) AS id       \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                        WHERE\n",
    "                            concept_id IN (133835)       \n",
    "                            AND full_text LIKE '%_rank1]%'      ) a \n",
    "                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                            OR c.path LIKE CONCAT('%.', a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                            OR c.path = a.id) \n",
    "                    WHERE\n",
    "                        is_standard = 1 \n",
    "                        AND is_selectable = 1) \n",
    "                    AND is_standard = 1 )) criteria ) )\"\"\"\n",
    "\n",
    "dataset_57765325_person_df = pandas.read_gbq(\n",
    "    dataset_57765325_person_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_57765325_person_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"Eczema\" for domain \"survey\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_88415271_survey_sql = \"\"\"\n",
    "    SELECT\n",
    "        answer.person_id,\n",
    "        answer.survey_datetime,\n",
    "        answer.survey,\n",
    "        answer.question_concept_id,\n",
    "        answer.question,\n",
    "        answer.answer_concept_id,\n",
    "        answer.answer,\n",
    "        answer.survey_version_concept_id,\n",
    "        answer.survey_version_name  \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".ds_survey` answer   \n",
    "    WHERE\n",
    "        (\n",
    "            question_concept_id IN (SELECT\n",
    "                DISTINCT concept_id                         \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c                         \n",
    "            JOIN\n",
    "                (SELECT\n",
    "                    CAST(cr.id as string) AS id                               \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr                               \n",
    "                WHERE\n",
    "                    concept_id IN (1586134, 1585855, 1585710, 43528895, 40192389, 1740639)                               \n",
    "                    AND domain_id = 'SURVEY') a \n",
    "                    ON (c.path like CONCAT('%', a.id, '.%'))                         \n",
    "            WHERE\n",
    "                domain_id = 'SURVEY'                         \n",
    "                AND type = 'PPI'                         \n",
    "                AND subtype = 'QUESTION')\n",
    "        )  \n",
    "        AND (\n",
    "            answer.PERSON_ID IN (SELECT\n",
    "                distinct person_id  \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "            WHERE\n",
    "                cb_search_person.person_id IN (SELECT\n",
    "                    criteria.person_id \n",
    "                FROM\n",
    "                    (SELECT\n",
    "                        DISTINCT person_id, entry_date, concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                    WHERE\n",
    "                        (concept_id IN(SELECT\n",
    "                            DISTINCT c.concept_id \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                        JOIN\n",
    "                            (SELECT\n",
    "                                CAST(cr.id as string) AS id       \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                            WHERE\n",
    "                                concept_id IN (133835)       \n",
    "                                AND full_text LIKE '%_rank1]%'      ) a \n",
    "                                ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                                OR c.path LIKE CONCAT('%.', a.id) \n",
    "                                OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                                OR c.path = a.id) \n",
    "                        WHERE\n",
    "                            is_standard = 1 \n",
    "                            AND is_selectable = 1) \n",
    "                        AND is_standard = 1 )) criteria ) )\n",
    "        )\"\"\"\n",
    "\n",
    "dataset_88415271_survey_df = pandas.read_gbq(\n",
    "    dataset_88415271_survey_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_88415271_survey_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eczema_survey_processed = dataset_88415271_survey_df.groupby(['person_id', 'survey'])['answer'].agg('max').reset_index()\n",
    "eczema_survey_processed = eczema_survey_processed.pivot(index='person_id', columns='survey', values='answer')\n",
    "eczema_survey_processed = eczema_survey_processed.reset_index()\n",
    "eczema_survey_processed.fillna('unknown', inplace=True)\n",
    "\n",
    "del dataset_88415271_survey_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"Eczema\" for domain \"fitbit_heart_rate_summary\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_57765325_fitbit_heart_rate_summary_sql = \"\"\"\n",
    "    SELECT\n",
    "        heart_rate_summary.person_id,\n",
    "        heart_rate_summary.date,\n",
    "        heart_rate_summary.zone_name,\n",
    "        heart_rate_summary.min_heart_rate,\n",
    "        heart_rate_summary.max_heart_rate,\n",
    "        heart_rate_summary.minute_in_zone,\n",
    "        heart_rate_summary.calorie_count \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".heart_rate_summary` heart_rate_summary   \n",
    "    WHERE\n",
    "        heart_rate_summary.PERSON_ID IN (SELECT\n",
    "            distinct person_id  \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "        WHERE\n",
    "            cb_search_person.person_id IN (SELECT\n",
    "                criteria.person_id \n",
    "            FROM\n",
    "                (SELECT\n",
    "                    DISTINCT person_id, entry_date, concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                WHERE\n",
    "                    (concept_id IN(SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                    JOIN\n",
    "                        (SELECT\n",
    "                            CAST(cr.id as string) AS id       \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                        WHERE\n",
    "                            concept_id IN (133835)       \n",
    "                            AND full_text LIKE '%_rank1]%'      ) a \n",
    "                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                            OR c.path LIKE CONCAT('%.', a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                            OR c.path = a.id) \n",
    "                    WHERE\n",
    "                        is_standard = 1 \n",
    "                        AND is_selectable = 1) \n",
    "                    AND is_standard = 1 )) criteria ) )\"\"\"\n",
    "\n",
    "dataset_57765325_fitbit_heart_rate_summary_df = pandas.read_gbq(\n",
    "    dataset_57765325_fitbit_heart_rate_summary_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_57765325_fitbit_heart_rate_summary_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitbit_heart_rate = (\n",
    "    dataset_57765325_fitbit_heart_rate_summary_df.groupby('person_id')\n",
    "    .agg(\n",
    "        mean_min_heart_rate = ('min_heart_rate', 'mean'),\n",
    "        mean_max_heart_rate = ('max_heart_rate', 'mean'),\n",
    "        mean_minute_in_zone=('minute_in_zone', 'mean'),\n",
    "        max_minute_in_zone=('minute_in_zone', 'max'),\n",
    "        heart_rate_count=('calorie_count', 'count'),\n",
    "        calorie_mean=('calorie_count', 'mean'),\n",
    "        calorie_max=('calorie_count', 'max'),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "fitbit_heart_rate\n",
    "\n",
    "del dataset_57765325_fitbit_heart_rate_summary_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"Eczema\" for domain \"fitbit_heart_rate_level\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_57765325_fitbit_heart_rate_level_sql = \"\"\"\n",
    "    SELECT\n",
    "        heart_rate_minute_level.person_id,\n",
    "        CAST(heart_rate_minute_level.datetime AS DATE) as date,\n",
    "        AVG(heart_rate_value) avg_rate \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".heart_rate_minute_level` heart_rate_minute_level   \n",
    "    WHERE\n",
    "        heart_rate_minute_level.PERSON_ID IN (SELECT\n",
    "            distinct person_id  \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "        WHERE\n",
    "            cb_search_person.person_id IN (SELECT\n",
    "                criteria.person_id \n",
    "            FROM\n",
    "                (SELECT\n",
    "                    DISTINCT person_id, entry_date, concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                WHERE\n",
    "                    (concept_id IN(SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                    JOIN\n",
    "                        (SELECT\n",
    "                            CAST(cr.id as string) AS id       \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                        WHERE\n",
    "                            concept_id IN (133835)       \n",
    "                            AND full_text LIKE '%_rank1]%'      ) a \n",
    "                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                            OR c.path LIKE CONCAT('%.', a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                            OR c.path = a.id) \n",
    "                    WHERE\n",
    "                        is_standard = 1 \n",
    "                        AND is_selectable = 1) \n",
    "                    AND is_standard = 1 )) criteria ) ) \n",
    "    GROUP BY\n",
    "        person_id,\n",
    "        date\"\"\"\n",
    "\n",
    "dataset_57765325_fitbit_heart_rate_level_df = pandas.read_gbq(\n",
    "    dataset_57765325_fitbit_heart_rate_level_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_57765325_fitbit_heart_rate_level_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitbit_avg_rate = (\n",
    "    dataset_57765325_fitbit_heart_rate_level_df.groupby('person_id')\n",
    "    .agg(\n",
    "        mean_avg_rate = ('avg_rate', 'mean'),\n",
    "        max_avg_rate = ('avg_rate', 'max'),\n",
    "        min_avg_rate=('avg_rate', 'min'),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "fitbit_avg_rate\n",
    "\n",
    "del dataset_57765325_fitbit_heart_rate_level_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"Eczema\" for domain \"fitbit_intraday_steps\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_57765325_fitbit_intraday_steps_sql = \"\"\"\n",
    "    SELECT\n",
    "        steps_intraday.person_id,\n",
    "        CAST(steps_intraday.datetime AS DATE) as date,\n",
    "        SUM(CAST(steps_intraday.steps AS INT64)) as sum_steps \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".steps_intraday` steps_intraday   \n",
    "    WHERE\n",
    "        steps_intraday.PERSON_ID IN (SELECT\n",
    "            distinct person_id  \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "        WHERE\n",
    "            cb_search_person.person_id IN (SELECT\n",
    "                criteria.person_id \n",
    "            FROM\n",
    "                (SELECT\n",
    "                    DISTINCT person_id, entry_date, concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                WHERE\n",
    "                    (concept_id IN(SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                    JOIN\n",
    "                        (SELECT\n",
    "                            CAST(cr.id as string) AS id       \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                        WHERE\n",
    "                            concept_id IN (133835)       \n",
    "                            AND full_text LIKE '%_rank1]%'      ) a \n",
    "                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                            OR c.path LIKE CONCAT('%.', a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                            OR c.path = a.id) \n",
    "                    WHERE\n",
    "                        is_standard = 1 \n",
    "                        AND is_selectable = 1) \n",
    "                    AND is_standard = 1 )) criteria ) ) \n",
    "    GROUP BY\n",
    "        person_id,\n",
    "        date\"\"\"\n",
    "\n",
    "dataset_57765325_fitbit_intraday_steps_df = pandas.read_gbq(\n",
    "    dataset_57765325_fitbit_intraday_steps_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_57765325_fitbit_intraday_steps_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitbit_sum_steps = (\n",
    "    dataset_57765325_fitbit_intraday_steps_df.groupby('person_id')\n",
    "    .agg(\n",
    "        mean_avg_steps = ('sum_steps', 'mean'),\n",
    "        max_avg_steps = ('sum_steps', 'max'),\n",
    "        min_avg_steps=('sum_steps', 'min'),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "fitbit_sum_steps\n",
    "\n",
    "del dataset_57765325_fitbit_intraday_steps_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"Eczema\" for domain \"fitbit_activity\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_57765325_fitbit_activity_sql = \"\"\"\n",
    "    SELECT\n",
    "        activity_summary.person_id,\n",
    "        activity_summary.date,\n",
    "        activity_summary.activity_calories,\n",
    "        activity_summary.calories_bmr,\n",
    "        activity_summary.calories_out,\n",
    "        activity_summary.elevation,\n",
    "        activity_summary.fairly_active_minutes,\n",
    "        activity_summary.floors,\n",
    "        activity_summary.lightly_active_minutes,\n",
    "        activity_summary.marginal_calories,\n",
    "        activity_summary.sedentary_minutes,\n",
    "        activity_summary.steps,\n",
    "        activity_summary.very_active_minutes \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".activity_summary` activity_summary   \n",
    "    WHERE\n",
    "        activity_summary.PERSON_ID IN (SELECT\n",
    "            distinct person_id  \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "        WHERE\n",
    "            cb_search_person.person_id IN (SELECT\n",
    "                criteria.person_id \n",
    "            FROM\n",
    "                (SELECT\n",
    "                    DISTINCT person_id, entry_date, concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                WHERE\n",
    "                    (concept_id IN(SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                    JOIN\n",
    "                        (SELECT\n",
    "                            CAST(cr.id as string) AS id       \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                        WHERE\n",
    "                            concept_id IN (133835)       \n",
    "                            AND full_text LIKE '%_rank1]%'      ) a \n",
    "                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                            OR c.path LIKE CONCAT('%.', a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                            OR c.path = a.id) \n",
    "                    WHERE\n",
    "                        is_standard = 1 \n",
    "                        AND is_selectable = 1) \n",
    "                    AND is_standard = 1 )) criteria ) )\"\"\"\n",
    "\n",
    "dataset_57765325_fitbit_activity_df = pandas.read_gbq(\n",
    "    dataset_57765325_fitbit_activity_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_57765325_fitbit_activity_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitbit_activity = (\n",
    "    dataset_57765325_fitbit_activity_df.groupby('person_id')\n",
    "    .agg(\n",
    "        mean_activity_calories = ('activity_calories', 'mean'),\n",
    "        max_activity_calories = ('activity_calories', 'max'),\n",
    "        min_activity_calories=('activity_calories', 'min'),\n",
    "        mean_fairly_active_minutes = ('fairly_active_minutes', 'mean'),\n",
    "        max_fairly_active_minutes = ('fairly_active_minutes', 'max'),\n",
    "        min_fairly_active_minutes=('fairly_active_minutes', 'min'),\n",
    "        mean_very_active_minutes = ('very_active_minutes', 'mean'),\n",
    "        max_very_active_minutes = ('very_active_minutes', 'max'),\n",
    "        min_very_active_minutes=('very_active_minutes', 'min'),\n",
    "        mean_steps = ('steps', 'mean'),\n",
    "        max_steps = ('steps', 'max'),\n",
    "        min_steps=('steps', 'min'),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "fitbit_activity\n",
    "\n",
    "\n",
    "del dataset_57765325_fitbit_activity_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"Eczema\" for domain \"fitbit_sleep_daily_summary\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_57765325_fitbit_sleep_daily_summary_sql = \"\"\"\n",
    "    SELECT\n",
    "        sleep_daily_summary.person_id,\n",
    "        sleep_daily_summary.sleep_date,\n",
    "        sleep_daily_summary.is_main_sleep,\n",
    "        sleep_daily_summary.minute_in_bed,\n",
    "        sleep_daily_summary.minute_asleep,\n",
    "        sleep_daily_summary.minute_after_wakeup,\n",
    "        sleep_daily_summary.minute_awake,\n",
    "        sleep_daily_summary.minute_restless,\n",
    "        sleep_daily_summary.minute_deep,\n",
    "        sleep_daily_summary.minute_light,\n",
    "        sleep_daily_summary.minute_rem,\n",
    "        sleep_daily_summary.minute_wake \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".sleep_daily_summary` sleep_daily_summary   \n",
    "    WHERE\n",
    "        PERSON_ID IN (SELECT\n",
    "            distinct person_id  \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "        WHERE\n",
    "            cb_search_person.person_id IN (SELECT\n",
    "                criteria.person_id \n",
    "            FROM\n",
    "                (SELECT\n",
    "                    DISTINCT person_id, entry_date, concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                WHERE\n",
    "                    (concept_id IN(SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                    JOIN\n",
    "                        (SELECT\n",
    "                            CAST(cr.id as string) AS id       \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                        WHERE\n",
    "                            concept_id IN (133835)       \n",
    "                            AND full_text LIKE '%_rank1]%'      ) a \n",
    "                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                            OR c.path LIKE CONCAT('%.', a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                            OR c.path = a.id) \n",
    "                    WHERE\n",
    "                        is_standard = 1 \n",
    "                        AND is_selectable = 1) \n",
    "                    AND is_standard = 1 )) criteria ) )\"\"\"\n",
    "\n",
    "dataset_57765325_fitbit_sleep_daily_summary_df = pandas.read_gbq(\n",
    "    dataset_57765325_fitbit_sleep_daily_summary_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_57765325_fitbit_sleep_daily_summary_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitbit_sleep = (\n",
    "    dataset_57765325_fitbit_sleep_daily_summary_df.groupby('person_id')\n",
    "    .agg(\n",
    "        mean_minute_asleep = ('minute_asleep', 'mean'),\n",
    "        max_minute_asleep = ('minute_asleep', 'max'),\n",
    "        min_minute_asleep=('minute_asleep', 'min'),\n",
    "        mean_minute_deep = ('minute_deep', 'mean'),\n",
    "        max_minute_deep = ('minute_deep', 'max'),\n",
    "        min_minute_deep=('minute_deep', 'min'),\n",
    "        mean_minute_rem = ('minute_rem', 'mean'),\n",
    "        max_minute_rem = ('minute_rem', 'max'),\n",
    "        min_minute_rem=('minute_rem', 'min'),\n",
    "        mean_minute_light = ('minute_light', 'mean'),\n",
    "        max_minute_light = ('minute_light', 'max'),\n",
    "        min_minute_light=('minute_light', 'min'),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "fitbit_sleep\n",
    "\n",
    "del dataset_57765325_fitbit_sleep_daily_summary_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset \"Eczema\" for domain \"zip_code_socioeconomic\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_57765325_zip_code_socioeconomic_sql = \"\"\"\n",
    "    SELECT\n",
    "        observation.person_id,\n",
    "        observation.observation_datetime,\n",
    "        zip_code.zip3_as_string as zip_code,\n",
    "        zip_code.fraction_assisted_income as assisted_income,\n",
    "        zip_code.fraction_high_school_edu as high_school_education,\n",
    "        zip_code.median_income,\n",
    "        zip_code.fraction_no_health_ins as no_health_insurance,\n",
    "        zip_code.fraction_poverty as poverty,\n",
    "        zip_code.fraction_vacant_housing as vacant_housing,\n",
    "        zip_code.deprivation_index,\n",
    "        zip_code.acs as american_community_survey_year \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".zip3_ses_map` zip_code \n",
    "    JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".observation` observation \n",
    "            ON CAST(SUBSTR(observation.value_as_string, 0, STRPOS(observation.value_as_string, '*') - 1) AS INT64) = zip_code.zip3  \n",
    "    WHERE\n",
    "        observation.PERSON_ID IN (SELECT\n",
    "            distinct person_id  \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "        WHERE\n",
    "            cb_search_person.person_id IN (SELECT\n",
    "                criteria.person_id \n",
    "            FROM\n",
    "                (SELECT\n",
    "                    DISTINCT person_id, entry_date, concept_id \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                WHERE\n",
    "                    (concept_id IN(SELECT\n",
    "                        DISTINCT c.concept_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                    JOIN\n",
    "                        (SELECT\n",
    "                            CAST(cr.id as string) AS id       \n",
    "                        FROM\n",
    "                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr       \n",
    "                        WHERE\n",
    "                            concept_id IN (133835)       \n",
    "                            AND full_text LIKE '%_rank1]%'      ) a \n",
    "                            ON (c.path LIKE CONCAT('%.', a.id, '.%') \n",
    "                            OR c.path LIKE CONCAT('%.', a.id) \n",
    "                            OR c.path LIKE CONCAT(a.id, '.%') \n",
    "                            OR c.path = a.id) \n",
    "                    WHERE\n",
    "                        is_standard = 1 \n",
    "                        AND is_selectable = 1) \n",
    "                    AND is_standard = 1 )) criteria ) ) \n",
    "        AND observation_source_concept_id = 1585250 \n",
    "        AND observation.value_as_string NOT LIKE 'Res%'\"\"\"\n",
    "\n",
    "dataset_57765325_zip_code_socioeconomic_df = pandas.read_gbq(\n",
    "    dataset_57765325_zip_code_socioeconomic_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_57765325_zip_code_socioeconomic_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eczema_merged = pd.merge(dataset_57765325_person_df, dataset_57765325_zip_code_socioeconomic_df, on='person_id', how='inner')\n",
    "eczema_merged = pd.merge(eczema_merged, fitbit_heart_rate, on='person_id', how='left')\n",
    "eczema_merged[fitbit_heart_rate.columns] = eczema_merged[fitbit_heart_rate.columns].fillna(-1)\n",
    "eczema_merged = pd.merge(eczema_merged, fitbit_avg_rate, on='person_id', how='left')\n",
    "eczema_merged[fitbit_avg_rate.columns] = eczema_merged[fitbit_avg_rate.columns].fillna(-1)\n",
    "eczema_merged = pd.merge(eczema_merged, fitbit_sum_steps, on='person_id', how='left')\n",
    "eczema_merged[fitbit_sum_steps.columns] = eczema_merged[fitbit_sum_steps.columns].fillna(-1)\n",
    "eczema_merged = pd.merge(eczema_merged, fitbit_activity, on='person_id', how='left')\n",
    "eczema_merged[fitbit_activity.columns] = eczema_merged[fitbit_activity.columns].fillna(-1)\n",
    "eczema_merged = pd.merge(eczema_merged, fitbit_sleep, on='person_id', how='left')\n",
    "eczema_merged[fitbit_sleep.columns] = eczema_merged[fitbit_sleep.columns].fillna(-1)\n",
    "eczema_merged = pd.merge(eczema_merged, eczema_survey_processed, on='person_id', how='left')\n",
    "eczema_merged[eczema_survey_processed.columns] = eczema_merged[eczema_survey_processed.columns].fillna('unknown')\n",
    "eczema_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset_57765325_person_df,eczema_survey_processed,\n",
    "fitbit_heart_rate, fitbit_sum_steps, fitbit_activity, fitbit_sleep, dataset_57765325_zip_code_socioeconomic_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset for domain \"person\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_66329268_person_sql = \"\"\"\n",
    "    SELECT\n",
    "        person.person_id,\n",
    "        person.gender_concept_id,\n",
    "        p_gender_concept.concept_name as gender,\n",
    "        person.birth_datetime as date_of_birth,\n",
    "        person.race_concept_id,\n",
    "        p_race_concept.concept_name as race,\n",
    "        person.ethnicity_concept_id,\n",
    "        p_ethnicity_concept.concept_name as ethnicity,\n",
    "        person.sex_at_birth_concept_id,\n",
    "        p_sex_at_birth_concept.concept_name as sex_at_birth \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".person` person \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_gender_concept \n",
    "            ON person.gender_concept_id = p_gender_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_race_concept \n",
    "            ON person.race_concept_id = p_race_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_ethnicity_concept \n",
    "            ON person.ethnicity_concept_id = p_ethnicity_concept.concept_id \n",
    "    LEFT JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` p_sex_at_birth_concept \n",
    "            ON person.sex_at_birth_concept_id = p_sex_at_birth_concept.concept_id\"\"\"\n",
    "\n",
    "dataset_66329268_person_df = pandas.read_gbq(\n",
    "    dataset_66329268_person_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_66329268_person_df.head(5)\n",
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset for domain \"zip_code_socioeconomic\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_66329268_zip_code_socioeconomic_sql = \"\"\"\n",
    "    SELECT\n",
    "        observation.person_id,\n",
    "        observation.observation_datetime,\n",
    "        zip_code.zip3_as_string as zip_code,\n",
    "        zip_code.fraction_assisted_income as assisted_income,\n",
    "        zip_code.fraction_high_school_edu as high_school_education,\n",
    "        zip_code.median_income,\n",
    "        zip_code.fraction_no_health_ins as no_health_insurance,\n",
    "        zip_code.fraction_poverty as poverty,\n",
    "        zip_code.fraction_vacant_housing as vacant_housing,\n",
    "        zip_code.deprivation_index,\n",
    "        zip_code.acs as american_community_survey_year \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".zip3_ses_map` zip_code \n",
    "    JOIN\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".observation` observation \n",
    "            ON CAST(SUBSTR(observation.value_as_string, 0, STRPOS(observation.value_as_string, '*') - 1) AS INT64) = zip_code.zip3 \n",
    "            AND observation_source_concept_id = 1585250 \n",
    "            AND observation.value_as_string NOT LIKE 'Res%'\"\"\"\n",
    "\n",
    "dataset_66329268_zip_code_socioeconomic_df = pandas.read_gbq(\n",
    "    dataset_66329268_zip_code_socioeconomic_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_66329268_zip_code_socioeconomic_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query represents dataset for domain \"fitbit_heart_rate_summary\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_29406193_fitbit_heart_rate_summary_sql = \"\"\"\n",
    "    SELECT\n",
    "        heart_rate_summary.person_id,\n",
    "        heart_rate_summary.date,\n",
    "        heart_rate_summary.zone_name,\n",
    "        heart_rate_summary.min_heart_rate,\n",
    "        heart_rate_summary.max_heart_rate,\n",
    "        heart_rate_summary.minute_in_zone,\n",
    "        heart_rate_summary.calorie_count \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".heart_rate_summary` heart_rate_summary \"\"\"\n",
    "\n",
    "dataset_29406193_fitbit_heart_rate_summary_df = pandas.read_gbq(\n",
    "    dataset_29406193_fitbit_heart_rate_summary_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_29406193_fitbit_heart_rate_summary_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitbit_heart_rate_all = (\n",
    "    dataset_29406193_fitbit_heart_rate_summary_df.groupby('person_id')\n",
    "    .agg(\n",
    "        mean_min_heart_rate = ('min_heart_rate', 'mean'),\n",
    "        mean_max_heart_rate = ('max_heart_rate', 'mean'),\n",
    "        mean_minute_in_zone=('minute_in_zone', 'mean'),\n",
    "        max_minute_in_zone=('minute_in_zone', 'max'),\n",
    "        heart_rate_count=('calorie_count', 'count'),\n",
    "        calorie_mean=('calorie_count', 'mean'),\n",
    "        calorie_max=('calorie_count', 'max'),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "del dataset_29406193_fitbit_heart_rate_summary_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset for domain \"fitbit_heart_rate_level\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_29406193_fitbit_heart_rate_level_sql = \"\"\"\n",
    "    SELECT\n",
    "        heart_rate_minute_level.person_id,\n",
    "        CAST(heart_rate_minute_level.datetime AS DATE) as date,\n",
    "        AVG(heart_rate_value) avg_rate \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".heart_rate_minute_level` heart_rate_minute_level  \n",
    "    GROUP BY\n",
    "        person_id,\n",
    "        date\"\"\"\n",
    "\n",
    "dataset_29406193_fitbit_heart_rate_level_df = pandas.read_gbq(\n",
    "    dataset_29406193_fitbit_heart_rate_level_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_29406193_fitbit_heart_rate_level_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitbit_avg_rate_all = (\n",
    "    dataset_29406193_fitbit_heart_rate_level_df.groupby('person_id')\n",
    "    .agg(\n",
    "        mean_avg_rate = ('avg_rate', 'mean'),\n",
    "        max_avg_rate = ('avg_rate', 'max'),\n",
    "        min_avg_rate=('avg_rate', 'min'),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "del dataset_29406193_fitbit_heart_rate_level_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query represents dataset for domain \"fitbit_activity\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_29406193_fitbit_activity_sql = \"\"\"\n",
    "    SELECT\n",
    "        activity_summary.person_id,\n",
    "        activity_summary.date,\n",
    "        activity_summary.activity_calories,\n",
    "        activity_summary.calories_bmr,\n",
    "        activity_summary.calories_out,\n",
    "        activity_summary.elevation,\n",
    "        activity_summary.fairly_active_minutes,\n",
    "        activity_summary.floors,\n",
    "        activity_summary.lightly_active_minutes,\n",
    "        activity_summary.marginal_calories,\n",
    "        activity_summary.sedentary_minutes,\n",
    "        activity_summary.steps,\n",
    "        activity_summary.very_active_minutes \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".activity_summary` activity_summary \"\"\"\n",
    "\n",
    "dataset_29406193_fitbit_activity_df = pandas.read_gbq(\n",
    "    dataset_29406193_fitbit_activity_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_29406193_fitbit_activity_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitbit_activity_all = (\n",
    "    dataset_29406193_fitbit_activity_df.groupby('person_id')\n",
    "    .agg(\n",
    "        mean_activity_calories = ('activity_calories', 'mean'),\n",
    "        max_activity_calories = ('activity_calories', 'max'),\n",
    "        min_activity_calories=('activity_calories', 'min'),\n",
    "        mean_fairly_active_minutes = ('fairly_active_minutes', 'mean'),\n",
    "        max_fairly_active_minutes = ('fairly_active_minutes', 'max'),\n",
    "        min_fairly_active_minutes=('fairly_active_minutes', 'min'),\n",
    "        mean_very_active_minutes = ('very_active_minutes', 'mean'),\n",
    "        max_very_active_minutes = ('very_active_minutes', 'max'),\n",
    "        min_very_active_minutes=('very_active_minutes', 'min'),\n",
    "        mean_steps = ('steps', 'mean'),\n",
    "        max_steps = ('steps', 'max'),\n",
    "        min_steps=('steps', 'min'),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "del dataset_29406193_fitbit_activity_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_29406193_fitbit_intraday_steps_sql = \"\"\"\n",
    "    SELECT\n",
    "        steps_intraday.person_id,\n",
    "        CAST(steps_intraday.datetime AS DATE) as date,\n",
    "        SUM(CAST(steps_intraday.steps AS INT64)) as sum_steps \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".steps_intraday` steps_intraday  \n",
    "    GROUP BY\n",
    "        person_id,\n",
    "        date\"\"\"\n",
    "\n",
    "dataset_29406193_fitbit_intraday_steps_df = pandas.read_gbq(\n",
    "    dataset_29406193_fitbit_intraday_steps_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_29406193_fitbit_intraday_steps_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitbit_sum_steps_all = (\n",
    "    dataset_29406193_fitbit_intraday_steps_df.groupby('person_id')\n",
    "    .agg(\n",
    "        mean_avg_steps = ('sum_steps', 'mean'),\n",
    "        max_avg_steps = ('sum_steps', 'max'),\n",
    "        min_avg_steps=('sum_steps', 'min'),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "del dataset_29406193_fitbit_intraday_steps_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query represents dataset for domain \"fitbit_sleep_daily_summary\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_29406193_fitbit_sleep_daily_summary_sql = \"\"\"\n",
    "    SELECT\n",
    "        sleep_daily_summary.person_id,\n",
    "        sleep_daily_summary.sleep_date,\n",
    "        sleep_daily_summary.is_main_sleep,\n",
    "        sleep_daily_summary.minute_in_bed,\n",
    "        sleep_daily_summary.minute_asleep,\n",
    "        sleep_daily_summary.minute_after_wakeup,\n",
    "        sleep_daily_summary.minute_awake,\n",
    "        sleep_daily_summary.minute_restless,\n",
    "        sleep_daily_summary.minute_deep,\n",
    "        sleep_daily_summary.minute_light,\n",
    "        sleep_daily_summary.minute_rem,\n",
    "        sleep_daily_summary.minute_wake \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".sleep_daily_summary` sleep_daily_summary \"\"\"\n",
    "\n",
    "dataset_29406193_fitbit_sleep_daily_summary_df = pandas.read_gbq(\n",
    "    dataset_29406193_fitbit_sleep_daily_summary_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_29406193_fitbit_sleep_daily_summary_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitbit_sleep_all = (\n",
    "    dataset_29406193_fitbit_sleep_daily_summary_df.groupby('person_id')\n",
    "    .agg(\n",
    "        mean_minute_asleep = ('minute_asleep', 'mean'),\n",
    "        max_minute_asleep = ('minute_asleep', 'max'),\n",
    "        min_minute_asleep=('minute_asleep', 'min'),\n",
    "        mean_minute_deep = ('minute_deep', 'mean'),\n",
    "        max_minute_deep = ('minute_deep', 'max'),\n",
    "        min_minute_deep=('minute_deep', 'min'),\n",
    "        mean_minute_rem = ('minute_rem', 'mean'),\n",
    "        max_minute_rem = ('minute_rem', 'max'),\n",
    "        min_minute_rem=('minute_rem', 'min'),\n",
    "        mean_minute_light = ('minute_light', 'mean'),\n",
    "        max_minute_light = ('minute_light', 'max'),\n",
    "        min_minute_light=('minute_light', 'min'),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "del dataset_29406193_fitbit_sleep_daily_summary_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_merged = pd.merge(dataset_66329268_person_df, dataset_66329268_zip_code_socioeconomic_df, on='person_id', how='inner')\n",
    "all_merged = pd.merge(all_merged, fitbit_heart_rate_all, on='person_id', how='left')\n",
    "all_merged[fitbit_heart_rate_all.columns] = all_merged[fitbit_heart_rate_all.columns].fillna(-1)\n",
    "all_merged = pd.merge(all_merged, fitbit_avg_rate_all, on='person_id', how='left')\n",
    "all_merged[fitbit_avg_rate_all.columns] = all_merged[fitbit_avg_rate_all.columns].fillna(-1)\n",
    "all_merged = pd.merge(all_merged, fitbit_sum_steps_all, on='person_id', how='left')\n",
    "all_merged[fitbit_sum_steps_all.columns] = all_merged[fitbit_sum_steps_all.columns].fillna(-1)\n",
    "all_merged = pd.merge(all_merged, fitbit_activity_all, on='person_id', how='left')\n",
    "all_merged[fitbit_activity_all.columns] = all_merged[fitbit_activity_all.columns].fillna(-1)\n",
    "all_merged = pd.merge(all_merged, fitbit_sleep_all, on='person_id', how='left')\n",
    "all_merged[fitbit_sleep_all.columns] = all_merged[fitbit_sleep_all.columns].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dataset_66329268_person_df, dataset_66329268_zip_code_socioeconomic_df, fitbit_heart_rate_all, fitbit_avg_rate_all, \n",
    "fitbit_sum_steps_all, fitbit_activity_all, fitbit_sleep_all\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset for domain \"survey\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_88696117_survey_sql = \"\"\"\n",
    "    SELECT\n",
    "        answer.person_id,\n",
    "        answer.survey_datetime,\n",
    "        answer.survey,\n",
    "        answer.question_concept_id,\n",
    "        answer.question,\n",
    "        answer.answer_concept_id,\n",
    "        answer.answer,\n",
    "        answer.survey_version_concept_id,\n",
    "        answer.survey_version_name  \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".ds_survey` answer   \n",
    "    WHERE\n",
    "        (\n",
    "            question_concept_id IN (SELECT\n",
    "                DISTINCT concept_id                         \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c                         \n",
    "            JOIN\n",
    "                (SELECT\n",
    "                    CAST(cr.id as string) AS id                               \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr                               \n",
    "                WHERE\n",
    "                    concept_id IN (1586134, 1585855, 1585710)                               \n",
    "                    AND domain_id = 'SURVEY') a \n",
    "                    ON (c.path like CONCAT('%', a.id, '.%'))                         \n",
    "            WHERE\n",
    "                domain_id = 'SURVEY'                         \n",
    "                AND type = 'PPI'                         \n",
    "                AND subtype = 'QUESTION')\n",
    "        )  \"\"\" \n",
    "\n",
    "dataset_88696117_survey_df = pandas.read_gbq(\n",
    "    dataset_88696117_survey_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_88696117_survey_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset for domain \"survey\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_88696117_survey_sql_2 = \"\"\"\n",
    "    SELECT\n",
    "        answer.person_id,\n",
    "        answer.survey_datetime,\n",
    "        answer.survey,\n",
    "        answer.question_concept_id,\n",
    "        answer.question,\n",
    "        answer.answer_concept_id,\n",
    "        answer.answer,\n",
    "        answer.survey_version_concept_id,\n",
    "        answer.survey_version_name  \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".ds_survey` answer   \n",
    "    WHERE\n",
    "        (\n",
    "            question_concept_id IN (SELECT\n",
    "                DISTINCT concept_id                         \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c                         \n",
    "            JOIN\n",
    "                (SELECT\n",
    "                    CAST(cr.id as string) AS id                               \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr                               \n",
    "                WHERE\n",
    "                    concept_id IN (43528895)                               \n",
    "                    AND domain_id = 'SURVEY') a \n",
    "                    ON (c.path like CONCAT('%', a.id, '.%'))                         \n",
    "            WHERE\n",
    "                domain_id = 'SURVEY'                         \n",
    "                AND type = 'PPI'                         \n",
    "                AND subtype = 'QUESTION')\n",
    "        )  \"\"\" \n",
    "\n",
    "dataset_88696117_survey_df_2 = pandas.read_gbq(\n",
    "    dataset_88696117_survey_sql_2,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_88696117_survey_df_2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "compiled_all_1 = pd.concat([dataset_88696117_survey_df, dataset_88696117_survey_df_2], ignore_index=True)\n",
    "\n",
    "del dataset_88696117_survey_df, dataset_88696117_survey_df_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_survey_processed_1 = compiled_all_1.groupby(['person_id', 'survey'])['answer'].agg('max').reset_index()\n",
    "\n",
    "del compiled_all_1\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset for domain \"survey\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_88696117_survey_sql_3 = \"\"\"\n",
    "    SELECT\n",
    "        answer.person_id,\n",
    "        answer.survey_datetime,\n",
    "        answer.survey,\n",
    "        answer.question_concept_id,\n",
    "        answer.question,\n",
    "        answer.answer_concept_id,\n",
    "        answer.answer,\n",
    "        answer.survey_version_concept_id,\n",
    "        answer.survey_version_name  \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".ds_survey` answer   \n",
    "    WHERE\n",
    "        (\n",
    "            question_concept_id IN (SELECT\n",
    "                DISTINCT concept_id                         \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c                         \n",
    "            JOIN\n",
    "                (SELECT\n",
    "                    CAST(cr.id as string) AS id                               \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr                               \n",
    "                WHERE\n",
    "                    concept_id IN (40192389)                               \n",
    "                    AND domain_id = 'SURVEY') a \n",
    "                    ON (c.path like CONCAT('%', a.id, '.%'))                         \n",
    "            WHERE\n",
    "                domain_id = 'SURVEY'                         \n",
    "                AND type = 'PPI'                         \n",
    "                AND subtype = 'QUESTION')\n",
    "        )  \"\"\" \n",
    "\n",
    "dataset_88696117_survey_df_3 = pandas.read_gbq(\n",
    "    dataset_88696117_survey_sql_3,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_88696117_survey_df_3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "\n",
    "# This query represents dataset for domain \"survey\" and was generated for All of Us Controlled Tier Dataset v7\n",
    "dataset_88696117_survey_sql_4 = \"\"\"\n",
    "    SELECT\n",
    "        answer.person_id,\n",
    "        answer.survey_datetime,\n",
    "        answer.survey,\n",
    "        answer.question_concept_id,\n",
    "        answer.question,\n",
    "        answer.answer_concept_id,\n",
    "        answer.answer,\n",
    "        answer.survey_version_concept_id,\n",
    "        answer.survey_version_name  \n",
    "    FROM\n",
    "        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".ds_survey` answer   \n",
    "    WHERE\n",
    "        (\n",
    "            question_concept_id IN (SELECT\n",
    "                DISTINCT concept_id                         \n",
    "            FROM\n",
    "                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c                         \n",
    "            JOIN\n",
    "                (SELECT\n",
    "                    CAST(cr.id as string) AS id                               \n",
    "                FROM\n",
    "                    `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr                               \n",
    "                WHERE\n",
    "                    concept_id IN (1740639)                               \n",
    "                    AND domain_id = 'SURVEY') a \n",
    "                    ON (c.path like CONCAT('%', a.id, '.%'))                         \n",
    "            WHERE\n",
    "                domain_id = 'SURVEY'                         \n",
    "                AND type = 'PPI'                         \n",
    "                AND subtype = 'QUESTION')\n",
    "        )  \"\"\" \n",
    "\n",
    "dataset_88696117_survey_df_4 = pandas.read_gbq(\n",
    "    dataset_88696117_survey_sql_3,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")\n",
    "\n",
    "dataset_88696117_survey_df_4.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_all_2 = pd.concat([dataset_88696117_survey_df_3, dataset_88696117_survey_df_4], ignore_index=True)\n",
    "\n",
    "del dataset_88696117_survey_df_3, dataset_88696117_survey_df_4\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_survey_processed_2 = compiled_all_2.groupby(['person_id', 'survey'])['answer'].agg('max').reset_index()\n",
    "\n",
    "del compiled_all_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_survey_processed = pd.concat([all_survey_processed_1, all_survey_processed_2], ignore_index=True)\n",
    "del all_survey_processed_1, all_survey_processed_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_survey_processed = all_survey_processed.pivot(index='person_id', columns='survey', values='answer')\n",
    "all_survey_processed = all_survey_processed.reset_index()\n",
    "all_survey_processed.fillna('unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_survey_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eczema_rows = all_survey_processed[all_survey_processed['Lifestyle'].str.contains('Opioids', case=False, na=False)]\n",
    "eczema_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_merged = pd.merge(all_merged, all_survey_processed, on='person_id', how='left')\n",
    "all_merged[all_survey_processed.columns] = all_merged[all_survey_processed.columns].fillna('unknown')\n",
    "del all_survey_processed\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eczema_merged['Eczema'] = 1\n",
    "all_merged['Eczema'] = 0\n",
    "combined_df = pd.concat([eczema_merged, all_merged])\n",
    "final_df = combined_df.sort_values('Eczema', ascending=False).drop_duplicates(subset=['person_id'])\n",
    "final_df.reset_index(drop=True, inplace=True)\n",
    "# zipcode = final_df['zip_code'].tolist()\n",
    "# final_df.loc[:,'zip_code'] = [int(zc.replace(\"**\", \"\")) for zc in zipcode]\n",
    "# final_df['zip_code'] = pd.to_numeric(final_df['zip_code'], errors='coerce')\n",
    "final_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "white_only = final_df[final_df['race'] == 'White']\n",
    "white_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_only.loc[:, 'year_of_birth'] = white_only['date_of_birth'].dt.year\n",
    "white_only = white_only.drop(['person_id', 'race', 'race_concept_id', 'gender_concept_id', 'ethnicity_concept_id','sex_at_birth_concept_id', 'observation_datetime', 'date_of_birth'], axis = 1)\n",
    "cat_columns = white_only.select_dtypes(include=['object', 'category']).columns\n",
    "whites_encoded = pd.get_dummies(white_only, columns=cat_columns, drop_first=True)\n",
    "whites_encoded['year_of_birth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_no_ecz = whites_encoded.drop(columns = ['Eczema'])\n",
    "y = whites_encoded['Eczema']\n",
    "\n",
    "white_column_check = white_no_ecz.columns\n",
    "white_dtype = white_no_ecz.dtypes.tolist()\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(white_no_ecz) \n",
    "# pca = PCA(n_components=0.95)\n",
    "# X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(white_no_ecz, y, test_size=0.2, random_state=13)\n",
    "\n",
    "model = RandomForestClassifier(random_state=95, class_weight = 'balanced')\n",
    "\n",
    "# model = BaggingClassifier(base_estimator=base_model, \n",
    "#                                    n_estimators=10,  # Number of models to bag\n",
    "#                                    max_samples=0.8,  # Fraction of training data per model\n",
    "#                                    max_features=0.8,  # Fraction of features per model\n",
    "#                                    random_state=42,\n",
    "#                                    bootstrap=True)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure()\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"Reds\", fmt=\"d\", xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "plt.title('White Population Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = X_train.columns\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "feature_importance_df = feature_importance_df.drop(1)\n",
    "top_features = feature_importance_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del white_only, whites_encoded, X_train, X_test, y_train, y_test, cat_columns\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_white = white_no_ecz[top_features['Feature'].tolist()]\n",
    "del white_no_ecz\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_top, X_test_top, y_train_top, y_test_top = train_test_split(top_white, y, test_size=0.2, random_state=13)\n",
    "model_top = RandomForestClassifier(random_state=95, class_weight = 'balanced')\n",
    "\n",
    "model_top.fit(X_train_top, y_train_top)\n",
    "y_pred_top = model_top.predict(X_test_top)\n",
    "cm_top = confusion_matrix(y_test_top, y_pred_top)\n",
    "\n",
    "accuracy_topw = accuracy_score(y_test_top, y_pred_top)\n",
    "conf_matrix_topw = confusion_matrix(y_test_top, y_pred_top)\n",
    "\n",
    "print(f'Accuracy: {accuracy_topw}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_topw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.heatmap(conf_matrix_topw, annot=True, cmap=\"Reds\", fmt=\"d\", xticklabels=np.unique(y_test_top), yticklabels=np.unique(y_test_top))\n",
    "plt.title('White Population Confusion Matrix (Top Features)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X_train_top, X_test_top, y_train_top, y_test_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacks_only = final_df[final_df['race'] == 'Black or African American']\n",
    "blacks_only.loc[:, 'year_of_birth'] = blacks_only['date_of_birth'].dt.year\n",
    "blacks_only = blacks_only.drop(['person_id', 'race', 'race_concept_id', 'gender_concept_id', 'ethnicity_concept_id','sex_at_birth_concept_id', 'observation_datetime', 'date_of_birth'], axis = 1)\n",
    "cat_columns_blacks = blacks_only.select_dtypes(include=['object', 'category']).columns\n",
    "blacks_encoded = pd.get_dummies(blacks_only, columns=cat_columns_blacks, drop_first=True)\n",
    "X_blacks = blacks_encoded.drop(columns = ['Eczema'])\n",
    "y_blacks = blacks_encoded['Eczema']\n",
    "\n",
    "del blacks_only, blacks_encoded, cat_columns_blacks, final_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_diff = set(white_column_check) - set(X_blacks.columns)\n",
    "column_diff = list(column_diff)\n",
    "blacks_dict = {column_diff[i]: 'unknown' if white_dtype[i] == object else 0 for i in range(len(column_diff))}\n",
    "add_df_blacks = pd.DataFrame(blacks_dict, index=X_blacks.index)\n",
    "\n",
    "X_blacks_full = pd.concat([X_blacks, add_df_blacks], axis=1)\n",
    "    \n",
    "X_blacks_full = X_blacks_full[white_column_check]\n",
    "X_blacks_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_blacks = model.predict(X_blacks_full)\n",
    "accuracy_blacks = accuracy_score(y_blacks, y_pred_blacks)\n",
    "conf_matrix_blacks = confusion_matrix(y_blacks, y_pred_blacks)\n",
    "\n",
    "print(f'Accuracy: {accuracy_blacks}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_blacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.heatmap(conf_matrix_blacks, annot=True, cmap=\"Reds\", fmt=\"d\", xticklabels=np.unique(y_blacks), yticklabels=np.unique(y_blacks))\n",
    "plt.title('Black Population Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_black = X_blacks[top_features['Feature'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_blacks_top = model_top.predict(top_black)\n",
    "accuracy_topb = accuracy_score(y_blacks, y_pred_blacks_top)\n",
    "conf_matrix_blacks_topb = confusion_matrix(y_blacks, y_pred_blacks_top)\n",
    "\n",
    "print(f'Accuracy: {accuracy_topb}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_blacks_topb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.heatmap(conf_matrix_blacks_topb, annot=True, cmap=\"Reds\", fmt=\"d\", xticklabels=np.unique(y_blacks), yticklabels=np.unique(y_blacks))\n",
    "plt.title('Black Population Confusion Matrix (Top Features)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features.to_csv('top_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# Create a download link\n",
    "FileLink(r'top_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
